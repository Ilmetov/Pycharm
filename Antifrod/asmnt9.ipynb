{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = data[data['true']*data['pred'] == 1]\n",
    "FP = data[(data['true'] == 0) & (data['pred'] == 1)]\n",
    "FN = data[(data['true'] == 1) & (data['pred'] == 0)]\n",
    "TN = data[(data['true'] == 0) & (data['pred'] == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('A9-1.answ', 'w') as a:\n",
    "    a.write(str(TP.shape[0])+\" \"+str(FP.shape[0])+\" \"+str(FN.shape[0])+\" \"+str(TN.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = round(metrics.accuracy_score(data['true'],data['pred']),2)\n",
    "precision = round(metrics.precision_score(data['true'],data['pred']),2)\n",
    "recall = round(metrics.recall_score(data['true'],data['pred']),2)\n",
    "f1 = round(metrics.f1_score(data['true'],data['pred']),2)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('A9-2.answ', 'w') as a:\n",
    "    a.write(str(accuracy)+\" \"+str(precision)+\" \"+str(recall)+\" \"+str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>score_logreg</th>\n",
       "      <th>score_svm</th>\n",
       "      <th>score_knn</th>\n",
       "      <th>score_tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.683832</td>\n",
       "      <td>0.145976</td>\n",
       "      <td>0.787063</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.801966</td>\n",
       "      <td>0.239511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.382315</td>\n",
       "      <td>-0.245701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.506797</td>\n",
       "      <td>-0.137058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.488781</td>\n",
       "      <td>-0.154148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "data2 = pd.read_csv('scores.csv')\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_tbl = pd.DataFrame(columns=['rocauc', 'precision', 'recall', 'threshold'],index=['log','svm','knn','tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_tbl.rocauc['log'] = metrics.roc_auc_score(data2['true'],data2['score_logreg'])\n",
    "method_tbl.rocauc['svm'] = metrics.roc_auc_score(data2['true'],data2['score_svm'])\n",
    "method_tbl.rocauc['knn'] = metrics.roc_auc_score(data2['true'],data2['score_knn'])\n",
    "method_tbl.rocauc['tree'] = metrics.roc_auc_score(data2['true'],data2['score_tree'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('A9-3.answ', 'w') as a:\n",
    "    a.write(method_tbl.rocauc['log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = metrics.precision_recall_curve(data2.true,data2.score_logreg)\n",
    "precision = pd.DataFrame(precision,index=np.arange(precision.size))\n",
    "recall = pd.DataFrame(recall,index=np.arange(recall.size))\n",
    "threshold = pd.DataFrame(threshold,index=np.arange(threshold.size))\n",
    "recall_ind = recall[recall[0] >= .7].index\n",
    "prec_short = precision[precision.index.isin(recall_ind)]\n",
    "p_log = prec_short.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = metrics.precision_recall_curve(data2.true,data2.score_svm)\n",
    "precision = pd.DataFrame(precision,index=np.arange(precision.size))\n",
    "recall = pd.DataFrame(recall,index=np.arange(recall.size))\n",
    "threshold = pd.DataFrame(threshold,index=np.arange(threshold.size))\n",
    "recall_ind = recall[recall[0] >= .7].index\n",
    "prec_short = precision[precision.index.isin(recall_ind)]\n",
    "p_svm = prec_short.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = metrics.precision_recall_curve(data2.true,data2.score_knn)\n",
    "precision = pd.DataFrame(precision,index=np.arange(precision.size))\n",
    "recall = pd.DataFrame(recall,index=np.arange(recall.size))\n",
    "threshold = pd.DataFrame(threshold,index=np.arange(threshold.size))\n",
    "recall_ind = recall[recall[0] >= .7].index\n",
    "prec_short = precision[precision.index.isin(recall_ind)]\n",
    "p_knn = prec_short.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = metrics.precision_recall_curve(data2.true,data2.score_tree)\n",
    "precision = pd.DataFrame(precision,index=np.arange(precision.size))\n",
    "recall = pd.DataFrame(recall,index=np.arange(recall.size))\n",
    "threshold = pd.DataFrame(threshold,index=np.arange(threshold.size))\n",
    "recall_ind = recall[recall[0] >= .7].index\n",
    "prec_short = precision[precision.index.isin(recall_ind)]\n",
    "p_tree = prec_short.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = pd.DataFrame([p_log,p_svm,p_knn,p_tree],index=['score_logreg','score_svm','score_knn','score_tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score_tree</th>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_svm</th>\n",
       "      <td>0.622807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_logreg</th>\n",
       "      <td>0.630252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_knn</th>\n",
       "      <td>0.606557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "prec.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('A9-4.answ', 'w') as a:\n",
    "    a.write('score_tree')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}